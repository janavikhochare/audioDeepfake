{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.models import load_model\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from keras.layers import Activation, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Conv1D, Dropout, BatchNormalization, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add, Lambda, Concatenate, SpatialDropout1D\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Activation, Dense, Conv1D, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.models import load_model, Model\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from  keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "target_size = (256,256)\n",
    "color_mode = 'grayscale'\n",
    "dataset = '/raid/audio_detection/audio_detection/data'\n",
    "dataset_1= 'new'\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "print(os.getcwd())\n",
    "print(os.chdir(dataset))\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(f'{dataset}/train/', target_size=target_size, batch_size = batch_size,class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "val_generator = val_datagen.flow_from_directory(f'{dataset}/val/', target_size=target_size, batch_size = batch_size,class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "test_generator = test_datagen.flow_from_directory(f'{dataset}/test/', target_size=target_size, batch_size = batch_size,class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_generator)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customPooling(x):\n",
    "    target = x[1]\n",
    "    inputs = x[0]\n",
    "    maskVal = 0\n",
    "    #getting the mask by observing the model's inputs\n",
    "    mask = K.equal(inputs, maskVal)\n",
    "    mask = K.all(mask, axis=-1, keepdims=True)\n",
    "\n",
    "    #inverting the mask for getting the valid steps for each sample\n",
    "    mask = 1 - K.cast(mask, K.floatx())\n",
    "\n",
    "    #summing the valid steps for each sample\n",
    "    stepsPerSample = K.sum(mask, axis=1, keepdims=False)\n",
    "\n",
    "    #applying the mask to the target (to make sure you are summing zeros below)\n",
    "    target = target * mask\n",
    "\n",
    "    #calculating the mean of the steps (using our sum of valid steps as averager)\n",
    "    means = K.sum(target, axis=1, keepdims=False) / stepsPerSample\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_convnet():\n",
    "    #K.clear_session()\n",
    "    input_shape  = (256,256,1)\n",
    "    img_input = Input(input_shape, name='image_input')\n",
    "    #Reshape((3, 4), input_shape=(12,))\n",
    "    image_input = Reshape((256,256), input_shape= input_shape)(img_input)\n",
    "    num_conv_blocks = 8\n",
    "    init_neurons = 32\n",
    "    spatial_dropout_fraction = 0.05\n",
    "    num_dense_layers = 2\n",
    "    num_dense_neurons = 50\n",
    "    learning_rate = 0.0001\n",
    "    #model_params['residual_con'] = 2\n",
    "    convnet = []\n",
    "    convnet_5 = []\n",
    "    convnet_7 = []\n",
    "    for ly in range(0, num_conv_blocks):\n",
    "        if ly == 0:\n",
    "            convnet.append(Conv1D(init_neurons, 3, strides=1, activation='linear', padding='causal')(image_input))\n",
    "            print(convnet)\n",
    "            convnet_5.append(Conv1D(init_neurons, 5, strides=1, activation='linear', padding='causal')(image_input))\n",
    "            convnet_7.append(Conv1D(init_neurons, 7, strides=1, activation='linear', padding='causal')(image_input))\n",
    "        else:\n",
    "            convnet.append(\n",
    "                Conv1D(init_neurons * (ly * 2), 3, strides=1, activation='linear', padding='causal')(convnet[ly - 1]))\n",
    "            convnet_5.append(\n",
    "                Conv1D(init_neurons * (ly * 2), 5, strides=1, activation='linear', padding='causal')(convnet_5[ly - 1]))\n",
    "            convnet_7.append(\n",
    "                Conv1D(init_neurons * (ly * 2), 7, strides=1, activation='linear', padding='causal')(convnet_7[ly - 1]))\n",
    "\n",
    "        convnet[ly] = LeakyReLU()(convnet[ly])\n",
    "        convnet_5[ly] = LeakyReLU()(convnet_5[ly])\n",
    "        convnet_7[ly] = LeakyReLU()(convnet_7[ly])\n",
    "        if (ly - 2) >= 0:\n",
    "            res_conv = Conv1D(init_neurons * (ly * 2), 1, strides=1, activation='linear', padding='same')(\n",
    "                convnet[ly - 2])\n",
    "            convnet[ly] = Add(name=f'residual_con_3_{ly}')([convnet[ly], res_conv])\n",
    "            res_conv_5 = Conv1D(init_neurons * (ly * 2), 1, strides=1, activation='linear', padding='same')(\n",
    "                convnet_5[ly - 2])\n",
    "            convnet_5[ly] = Add(name=f'residual_con_5_{ly}')([convnet_5[ly], res_conv_5])\n",
    "            res_conv_7 = Conv1D(init_neurons * (ly * 2), 1, strides=1, activation='linear', padding='same')(\n",
    "                convnet_7[ly - 2])\n",
    "            convnet_7[ly] = Add(name=f'residual_con_7_{ly}')([convnet_7[ly], res_conv_7])\n",
    "\n",
    "        if ly<(num_conv_blocks-1):\n",
    "            convnet[ly] = SpatialDropout1D(spatial_dropout_fraction)(convnet[ly])\n",
    "            convnet_5[ly] = SpatialDropout1D(spatial_dropout_fraction)(convnet_5[ly])\n",
    "            convnet_7[ly] = SpatialDropout1D(spatial_dropout_fraction)(convnet_7[ly])\n",
    "\n",
    "    dense = Lambda(lambda x: customPooling(x))([image_input,convnet[ly]])\n",
    "    dense_5 = Lambda(lambda x: customPooling(x))([image_input,convnet_5[ly]])\n",
    "    dense_7 = Lambda(lambda x: customPooling(x))([image_input,convnet_7[ly]])\n",
    "\n",
    "    dense = Concatenate()([dense, dense_5, dense_7])\n",
    "\n",
    "    for layers in range(num_dense_layers):\n",
    "        dense = Dense(num_dense_neurons, activation='linear')(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dense = LeakyReLU()(dense)\n",
    "        dense = Dropout(0)(dense)\n",
    "        print(0)\n",
    "    output_layer = Dense(1)(dense)\n",
    "    output_layer = Activation('sigmoid')(output_layer)\n",
    "    model = Model(inputs=img_input, outputs=output_layer)\n",
    "    opt = optimizers.Adam(lr=learning_rate)\n",
    "    print(\"1\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/raid/audio_detection/audio_detection/data/models/raid/audio_detection/audio_detection/data_0tcn-janavi-epochs:20_acc:0.9801.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os     \n",
    "os.environ[\"PATH\"] += os.pathsep + '/usr/local/lib/python3.6/dist-packages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)\n",
    "predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(predictions,(64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions[:].astype(int)\n",
    "for i in predictions:\n",
    "    if i[0] < 0.5:\n",
    "        i[0] = 0.0\n",
    "    else :\n",
    "        i[0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y,predictions, labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = classification_report(y,predictions,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
