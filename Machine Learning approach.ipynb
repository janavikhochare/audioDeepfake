{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install libsndfile-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import librosa\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_train.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "data = pd.read_csv('dataset_dev.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_dev = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_dev = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "data = pd.read_csv('dataset_eval.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_eval = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_eval = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "print('Train')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))\n",
    "print()\n",
    "y_pred = clf.predict(X_dev)\n",
    "print('Dev')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_dev, y_pred))\n",
    "print()\n",
    "y_pred = clf.predict(X_eval)\n",
    "print('Eval')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "training_start = time.perf_counter()\n",
    "\n",
    "X_test= X_eval\n",
    "y_test= y_eval\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "\n",
    "prediction_start = time.perf_counter()\n",
    "preds = clf.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "\n",
    "acc_clf = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "clf_train_time = training_end-training_start\n",
    "clf_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's Random Forest Classifier's prediction accuracy is: %3.2f\" % (acc_clf))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (clf_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (clf_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "df_rfc = pd.DataFrame({'Class': np.unique(preds) ,\n",
    "             'Precision': precision_score(y_test, preds, average=None).round(4)*100,\n",
    "              'Recall': recall_score(y_test, preds, average=None).round(4)*100,\n",
    "              'F-Score': f1_score(y_test, preds, average=None).round(4)*100\n",
    "             })\n",
    "\n",
    "display(df_rfc)\n",
    "\n",
    "pre_rfc=precision_score(y_test, preds, average='weighted')*100\n",
    "rec_rfc=recall_score(y_test, preds, average='weighted')*100\n",
    "f1_rfc=f1_score(y_test, preds, average='weighted')*100\n",
    "acc_rfc=accuracy_score(y_test, preds)*100\n",
    "\n",
    "print('Metrics:\\n')\n",
    "print('Precision: %.2f%%' % (pre_rfc))\n",
    "print('Recall: %.2f%%' % (rec_rfc))\n",
    "print('F_score: %.2f%%' % (f1_rfc))\n",
    "print('Accuracy: %.2f%%'% (acc_rfc))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_train)\n",
    "print('Train')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))\n",
    "print()\n",
    "y_pred = rfc.predict(X_dev)\n",
    "print('Dev')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_dev, y_pred))\n",
    "print()\n",
    "y_pred = rfc.predict(X_eval)\n",
    "print('Eval')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "training_start = time.perf_counter()\n",
    "\n",
    "X_test= X_eval\n",
    "y_test= y_eval\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "# Model Fit and Predictions\n",
    "rfc.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "\n",
    "prediction_start = time.perf_counter()\n",
    "preds = rfc.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "\n",
    "acc_rfc = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "rfc_train_time = training_end-training_start\n",
    "rfc_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's Random Forest Classifier's prediction accuracy is: %3.2f\" % (acc_rfc))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (rfc_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (rfc_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "df_rfc = pd.DataFrame({'Class': np.unique(preds) ,\n",
    "             'Precision': precision_score(y_test, preds, average=None).round(4)*100,\n",
    "              'Recall': recall_score(y_test, preds, average=None).round(4)*100,\n",
    "              'F-Score': f1_score(y_test, preds, average=None).round(4)*100\n",
    "             })\n",
    "\n",
    "display(df_rfc)\n",
    "\n",
    "pre_rfc=precision_score(y_test, preds, average='weighted')*100\n",
    "rec_rfc=recall_score(y_test, preds, average='weighted')*100\n",
    "f1_rfc=f1_score(y_test, preds, average='weighted')*100\n",
    "acc_rfc=accuracy_score(y_test, preds)*100\n",
    "\n",
    "print('Metrics:\\n')\n",
    "print('Precision: %.2f%%' % (pre_rfc))\n",
    "print('Recall: %.2f%%' % (rec_rfc))\n",
    "print('F_score: %.2f%%' % (f1_rfc))\n",
    "print('Accuracy: %.2f%%'% (acc_rfc))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = time.perf_counter()\n",
    "knn.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = knn.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_knn = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "knn_train_time = training_end-training_start\n",
    "knn_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's K Nearest Neighbors Classifier's prediction accuracy is: %3.2f\" % (acc_knn))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (knn_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (knn_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = pd.DataFrame({'Class': np.unique(preds) ,\n",
    "             'Precision': precision_score(y_test, preds, average=None).round(4)*100,\n",
    "              'Recall': recall_score(y_test, preds, average=None).round(4)*100,\n",
    "              'F-Score': f1_score(y_test, preds, average=None).round(4)*100\n",
    "             })\n",
    "\n",
    "display(df_knn)\n",
    "\n",
    "pre_knn=precision_score(y_test, preds, average='weighted')*100\n",
    "rec_knn=recall_score(y_test, preds, average='weighted')*100\n",
    "f1_knn=f1_score(y_test, preds, average='weighted')*100\n",
    "acc_knn=accuracy_score(y_test, preds)*100\n",
    "\n",
    "print('Metrics:\\n')\n",
    "print('Precision: %.2f%%' % (pre_knn))\n",
    "print('Recall: %.2f%%' % (rec_knn))\n",
    "print('F_score: %.2f%%' % (f1_knn))\n",
    "print('Accuracy: %.2f%%'% (acc_knn))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb= XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = time.perf_counter()\n",
    "xgb.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = xgb.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "xgb_train_time = training_end-training_start\n",
    "xgb_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's XGBOOST prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (xgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_xgb = pd.DataFrame({'Class': np.unique(preds) ,\n",
    "             'Precision': precision_score(y_test, preds, average=None).round(4)*100,\n",
    "              'Recall': recall_score(y_test, preds, average=None).round(4)*100,\n",
    "              'F-Score': f1_score(y_test, preds, average=None).round(4)*100\n",
    "             })\n",
    "\n",
    "display(df_xgb)\n",
    "\n",
    "pre_xgb=precision_score(y_test, preds, average='weighted')*100\n",
    "rec_xgb=recall_score(y_test, preds, average='weighted')*100\n",
    "f1_xgb=f1_score(y_test, preds, average='weighted')*100\n",
    "acc_xgb=accuracy_score(y_test, preds)*100\n",
    "\n",
    "print('Metrics:\\n')\n",
    "print('Precision: %.2f%%' % (pre_xgb))\n",
    "print('Recall: %.2f%%' % (rec_xgb))\n",
    "print('F_score: %.2f%%' % (f1_xgb))\n",
    "print('Accuracy: %.2f%%'% (acc_xgb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LGBM\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 200,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "    #reg_alpha = 0.2,\n",
    "    #reg_lambda = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = time.perf_counter()\n",
    "lgb.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = lgb.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_lgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "lgb_train_time = training_end-training_start\n",
    "lgb_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's LGBM prediction accuracy is: %3.2f\" % (acc_lgb))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (lgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (lgb_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lgb = pd.DataFrame({'Class': np.unique(preds) ,\n",
    "             'Precision': precision_score(y_test, preds, average=None).round(4)*100,\n",
    "              'Recall': recall_score(y_test, preds, average=None).round(4)*100,\n",
    "              'F-Score': f1_score(y_test, preds, average=None).round(4)*100\n",
    "             })\n",
    "\n",
    "display(df_lgb)\n",
    "\n",
    "pre_lgb=precision_score(y_test, preds, average='weighted')*100\n",
    "rec_lgb=recall_score(y_test, preds, average='weighted')*100\n",
    "f1_lgb=f1_score(y_test, preds, average='weighted')*100\n",
    "acc_lgb=accuracy_score(y_test, preds)*100\n",
    "\n",
    "print('Metrics:\\n')\n",
    "print('Precision: %.2f%%' % (pre_lgb))\n",
    "print('Recall: %.2f%%' % (rec_lgb))\n",
    "print('F_score: %.2f%%' % (f1_lgb))\n",
    "print('Accuracy: %.2f%%'% (acc_lgb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(input_shape = (None, 37), lr = 1e-3):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    X = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    X = layers.LSTM(64, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(256, return_sequences=False)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(128, activation = 'relu')(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(1)(X)\n",
    "    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n",
    "    model = models.Model(inputs = inputs, outputs = X)\n",
    "    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset,modelpath in zip(['/raid/audio_detection/audio_detection/data'],['/raid/audio_detection/audio_detection/seniors/data_0epochs 08_acc 0.9997.h5']):\n",
    "    batch_size = 64\n",
    "    target_size = (256, 256)\n",
    "    color_mode = 'grayscale'\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_generator = val_datagen.flow_from_directory(f'{dataset}/val/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    test_generator = test_datagen.flow_from_directory(f'{dataset}/test/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "    model = small_cnn()\n",
    "    model.load_weights(modelpath)\n",
    "    print(f'Model: {modelpath}')\n",
    "    results = model.evaluate(val_generator,steps=2*len(val_generator),verbose=0)\n",
    "    print('Development Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n",
    "    results = model.evaluate(test_generator,steps=2*len(test_generator),verbose=0)\n",
    "    print('Evaluation Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]: .4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
