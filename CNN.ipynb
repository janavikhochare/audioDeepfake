{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_cnn(input_shape = (256, 256, 1), lr = 1e-4, factor = 16):\n",
    "    img_input = layers.Input(input_shape)\n",
    "#     X = layers.Conv2D(factor, 3, padding = 'same', activation = 'relu')(img_input)\n",
    "#     X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*2, 3, padding = 'same', activation = 'relu')(img_input)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*4, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*8, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*16, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(128, activation = 'relu')(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(1)(X)\n",
    "    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n",
    "    model = models.Model(inputs = img_input, outputs = X)\n",
    "    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "target_size = (256, 256)\n",
    "color_mode = 'grayscale'\n",
    "dataset = '/raid/audio_detection/audio_detection/data'\n",
    "dataset_1= 'new'\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "print(os.getcwd())\n",
    "print(os.chdir(dataset))\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(f'{dataset}/train/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "val_generator = val_datagen.flow_from_directory(f'{dataset}/val/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "test_generator = test_datagen.flow_from_directory(f'{dataset}/test/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "\n",
    "\n",
    "for attempt in range(1):\n",
    "    print(os.getcwd())\n",
    "    model_path = f'models/{dataset}_{attempt}'\n",
    "    print(os.getcwd())\n",
    "    Path(model_path).mkdir(parents=True, exist_ok = True)\n",
    "    checkpointer = ModelCheckpoint(model_path +'5_layers_lr_10e-4_epochs:{epoch:02d}_acc:{val_accuracy:.4f}.h5', monitor = 'val_loss', save_best_only = True, verbose = 0, mode = 'auto')\n",
    "    #checkpointer = ModelCheckpoint(filepath='model._epochs:{epoch:02d}_acc:{val_accuracy:.4f}.h5',monitor = 'val_loss', save_best_only = True, verbose = 0, mode = 'auto')\n",
    "    earlystopper = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 0, mode = 'auto')\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 1/np.sqrt(10), patience = 3, cooldown = 1, verbose = 0, mode = 'auto')\n",
    "    model = small_cnn((256,256,1))\n",
    "    history = model.fit(train_generator, steps_per_epoch = len(train_generator), verbose = 2, epochs = 50, callbacks = [checkpointer, earlystopper, reduceLR], validation_data=val_generator, validation_steps = len(val_generator))\n",
    "    print(model.evaluate(test_generator, steps = 2*len(test_generator)))\n",
    "    \n",
    "    ## added later on\n",
    "    results = model.evaluate(val_generator,steps=2*len(val_generator),verbose=0)\n",
    "    print('Development Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n",
    "    results = model.evaluate(test_generator,steps=2*len(test_generator),verbose=0)\n",
    "    print('Evaluation Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_csv_file = 'history_5_layers_lr_10e-4_layers.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
